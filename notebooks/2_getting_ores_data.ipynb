{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GirUXankMihp",
        "tags": []
      },
      "source": [
        "# Getting ORES scores through LiftWing ML Service API\n",
        "\n",
        "## Disclaimer\n",
        "Wikimedia Foundation (WMF) is reworking access to their APIs. It is likely in the coming years that all API access will require some kind of authentication, either through a simple key/token or through some version of OAuth. For now this is still a work in progress. You can follow the progress from their [API portal](https://api.wikimedia.org/wiki/Main_Page). Another on-going change is better control over API services in situations where those services require additional computational resources, beyond simply serving the text of a web page (i.e., the text of an article). Services like ORES that require running an ML model over the text of an article page is an example of a compute intensive API service.\n",
        "\n",
        "Wikimedia is implementing a new Machine Learning (ML) service infrastructure that they call [LiftWing](https://wikitech.wikimedia.org/wiki/Machine_Learning/LiftWing). Given that ORES already has several ML models that have been well used, ORES is the first set of APIs that are being moved to LiftWing.\n",
        "\n",
        "The code uses article quality estimates for article revisions using the LiftWing version of [ORES](https://www.mediawiki.org/wiki/ORES). The [ORES API documentation](https://ores.wikimedia.org) can be accessed from the main ORES page.\n",
        "\n",
        "\n",
        "## License\n",
        "This notebook uses parts of code and comments which were developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.0 - August 15, 2023\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ykGlc9LgMihs",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#\n",
        "# These are standard python modules\n",
        "import json, time, urllib.parse\n",
        "from dotenv import load_dotenv\n",
        "# The 'requests' module is not a standard Python module. You will need to install this with pip/pip3 if you do not already have it\n",
        "import requests\n",
        "import Constants as cs\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please note that in order to run the code form here you will need to create a file named Constants.py and add the following variables to it:\n",
        "\n",
        "```\n",
        "WIKIPEDIA_USERNAME = \"your wikipedia username here\"\n",
        "\n",
        "WIKIPEDIA_ACCESS_TOKEN = \"your wikipedia access token here\"\n",
        "```\n",
        "\n",
        "Use below infomation to get your own access token. \n",
        "\n",
        "## DANGER: THE CODE WILL NOT WORK WITHOUT THE Constants.py file.\n",
        "\n",
        "### How to get your own access token\n",
        "\n",
        "You will need a Wikimedia user account to get access to Lift Wing (the ML API service). You can either [create an account or login](https://api.wikimedia.org/w/index.php?title=Special:UserLogin). If you have a Wikipedia user account - you might already have an Wikimedia account. If you are not sure try your Wikipedia username and password to check it. If you do not have a Wikimedia account you will need to create an account that you can use to get an access token.\n",
        "\n",
        "There is [a 'guide' that describes how to get authentication tokens](https://api.wikimedia.org/wiki/Authentication) - but not everything works the way it is described in that documentation. You should review that documentation and then read the rest of this comment.\n",
        "\n",
        "The documentation talks about using a \"dashboard\" for managing authentication tokens. That's a rather generous description for what looks like a simple list of token things. You might have a hard time finding this \"dashboard\". First, on the left hand side of the page, you'll see a column of links. The bottom section is a set of links titled \"Tools\". In that section is a link that says [Special pages](https://api.wikimedia.org/wiki/Special:SpecialPages) which will take you to a list of ... well, special pages. At the very bottom of the \"Special pages\" page is a section titled \"Other special pages\" (scroll all the way to the bottom). The first link in that section is called [API keys](https://api.wikimedia.org/wiki/Special:AppManagement). When you get to the \"API keys\" page you can create a new key.\n",
        "\n",
        "The authentication guide suggests that you should create a server-side app key. This does not seem to work correctly - as yet. It failed on multiple attempts when I attempted to create a server-side app key. BUT, there is an option to create a [Personal API token](https://api.wikimedia.org/wiki/Authentication) that should work for this course and the type of ORES page scoring that you will need to perform.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jpwFSkXLMiht",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#########\n",
        "#\n",
        "#    CONSTANTS\n",
        "#\n",
        "\n",
        "#    The current LiftWing ORES API endpoint and prediction model\n",
        "#\n",
        "API_ORES_LIFTWING_ENDPOINT = \"https://api.wikimedia.org/service/lw/inference/v1/models/{model_name}:predict\"\n",
        "API_ORES_EN_QUALITY_MODEL = \"enwiki-articlequality\"\n",
        "\n",
        "#\n",
        "#    The throttling rate is a function of the Access token that you are granted when you request the token. The constants\n",
        "#    come from dissecting the token and getting the rate limits from the granted token. An example of that is below.\n",
        "#\n",
        "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
        "API_THROTTLE_WAIT = ((60.0*60.0)/5000.0)-API_LATENCY_ASSUMED  # The key authorizes 5000 requests per hour\n",
        "\n",
        "#    When making automated requests we should include something that is unique to the person making the request\n",
        "#    This should include an email - your UW email would be good to put in there\n",
        "#\n",
        "#    Because all LiftWing API requests require some form of authentication, you need to provide your access token\n",
        "#    as part of the header too\n",
        "#\n",
        "REQUEST_HEADER_TEMPLATE = {\n",
        "    'User-Agent': \"dabhinav@uw.edu, University of Washington, MSDS DATA 512 - AUTUMN 2024\",\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': \"Bearer {access_token}\"\n",
        "}\n",
        "#\n",
        "#    This is a template for the parameters that we need to supply in the headers of an API request\n",
        "#\n",
        "REQUEST_HEADER_PARAMS_TEMPLATE = {\n",
        "    'email_address' : \"\",         # your email address should go here\n",
        "    'access_token'  : \"\"          # the access token you create will need to go here\n",
        "}\n",
        "\n",
        "#\n",
        "#    A dictionary of English Wikipedia article titles (keys) and sample revision IDs that can be used for this ORES scoring example\n",
        "#\n",
        "ARTICLE_REVISIONS = { 'Bison':1085687913 , 'Northern flicker':1086582504 , 'Red squirrel':1083787665 , 'Chinook salmon':1085406228 , 'Horseshoe bat':1060601936 }\n",
        "\n",
        "#\n",
        "#    This is a template of the data required as a payload when making a scoring request of the ORES model\n",
        "#\n",
        "ORES_REQUEST_DATA_TEMPLATE = {\n",
        "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\n",
        "    \"rev_id\":      \"\",       # this request requires a revision id\n",
        "    \"features\":    True\n",
        "}\n",
        "\n",
        "#\n",
        "#    These are used later - defined here so they, at least, have empty values\n",
        "#\n",
        "USERNAME = cs.WIKIPEDIA_USERNAME\n",
        "ACCESS_TOKEN = cs.WIKIPEDIA_ACCESS_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk8t2G_IMihu"
      },
      "source": [
        "The Wikimedia Foundation appears to be issuing access tokens that are adhering to the [JWT (JSON Web Token) standard](https://jwt.io/introduction/). There was also some documentation by IBM about the [use of JWT tokens](https://www.ibm.com/docs/en/cics-ts/6.1?topic=cics-json-web-token-jwt) that I found useful. Keep in mind, documentation from IBM is specific to their implementation of the JWT standard. Access tokens are composed of different parts that specify the domain being accessed and rate limits. The little snippet of code below is not required to make ORES requests. It just allows us to see what is in the Wikimedia provided access token that you were issued."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnmeO3iSMihv"
      },
      "source": [
        "## Define a function to make the ORES API request\n",
        "\n",
        "The API request will be made using a function to encapsulate call and make access reusable in other notebooks. The procedure is parameterized, relying on the constants above for some important default parameters. The primary assumption is that this function will be used to request data for a set of article revisions. The main parameter is 'article_revid'. One should be able to simply pass in a new article revision id on each call and get back a python dictionary as the result. A valid result will be a dictionary that contains the probabilities that the specific revision is one of six different article quality levels. Generally, quality level with the highest probability score is considered the quality level for the article. This can be tricky when you have two (or more) highly probable quality levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "X_Ptriu0Mihv"
      },
      "outputs": [],
      "source": [
        "#########\n",
        "#\n",
        "#    PROCEDURES/FUNCTIONS\n",
        "#\n",
        "\n",
        "def request_ores_score_per_article(article_revid = None, email_address=None, access_token=None,\n",
        "                                   endpoint_url = API_ORES_LIFTWING_ENDPOINT,\n",
        "                                   model_name = API_ORES_EN_QUALITY_MODEL,\n",
        "                                   request_data = ORES_REQUEST_DATA_TEMPLATE,\n",
        "                                   header_format = REQUEST_HEADER_TEMPLATE,\n",
        "                                   header_params = REQUEST_HEADER_PARAMS_TEMPLATE):\n",
        "\n",
        "    #    Make sure we have an article revision id, email and token\n",
        "    #    This approach prioritizes the parameters passed in when making the call\n",
        "    if article_revid:\n",
        "        request_data['rev_id'] = article_revid\n",
        "    if email_address:\n",
        "        header_params['email_address'] = email_address\n",
        "    if access_token:\n",
        "        header_params['access_token'] = access_token\n",
        "\n",
        "    #   Making a request requires a revision id - an email address - and the access token\n",
        "    if not request_data['rev_id']:\n",
        "        raise Exception(\"Must provide an article revision id (rev_id) to score articles\")\n",
        "    if not header_params['email_address']:\n",
        "        raise Exception(\"Must provide an 'email_address' value\")\n",
        "    if not header_params['access_token']:\n",
        "        raise Exception(\"Must provide an 'access_token' value\")\n",
        "\n",
        "    # Create the request URL with the specified model parameter - default is a article quality score request\n",
        "    request_url = endpoint_url.format(model_name=model_name)\n",
        "\n",
        "    # Create a compliant request header from the template and the supplied parameters\n",
        "    headers = dict()\n",
        "    for key in header_format.keys():\n",
        "        headers[str(key)] = header_format[key].format(**header_params)\n",
        "\n",
        "    # make the request\n",
        "    try:\n",
        "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
        "        # occurs during the request processing - throttling is always a good practice with a free data\n",
        "        # source like ORES - or other community sources\n",
        "        if API_THROTTLE_WAIT > 0.0:\n",
        "            time.sleep(API_THROTTLE_WAIT)\n",
        "        #response = requests.get(request_url, headers=headers)\n",
        "        response = requests.post(request_url, headers=headers, data=json.dumps(request_data))\n",
        "        json_response = response.json()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        json_response = None\n",
        "    return json_response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need the rev_ids we got from the previous notebook to get the quality of the articles from ORES. FOr this we read the csv file and get the rev_ids from it.\n",
        "\n",
        "\n",
        "### Make sure to copy the csv file from the data_files folder and place it in the path of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ShXPbrAOx0d",
        "outputId": "d1a3379b-c446-4d4a-fcc2-9b0520e23023"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>revid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abdul Baqi Turkistani</td>\n",
              "      <td>1.231655e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abdul Ghani Ghani</td>\n",
              "      <td>1.227026e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abdul Rahim Ayoubi</td>\n",
              "      <td>1.226326e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ahmad Wali Massoud</td>\n",
              "      <td>1.221721e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Aimal Faizi</td>\n",
              "      <td>1.185106e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7150</th>\n",
              "      <td>Denis Walker</td>\n",
              "      <td>1.247903e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7151</th>\n",
              "      <td>Herbert Ushewokunze</td>\n",
              "      <td>9.591118e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7152</th>\n",
              "      <td>Josiah Tongogara</td>\n",
              "      <td>1.203429e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7153</th>\n",
              "      <td>Langton Towungana</td>\n",
              "      <td>1.246280e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7154</th>\n",
              "      <td>Sengezo Tshabangu</td>\n",
              "      <td>1.228478e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7155 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       name         revid\n",
              "0     Abdul Baqi Turkistani  1.231655e+09\n",
              "1         Abdul Ghani Ghani  1.227026e+09\n",
              "2        Abdul Rahim Ayoubi  1.226326e+09\n",
              "3        Ahmad Wali Massoud  1.221721e+09\n",
              "4               Aimal Faizi  1.185106e+09\n",
              "...                     ...           ...\n",
              "7150           Denis Walker  1.247903e+09\n",
              "7151    Herbert Ushewokunze  9.591118e+08\n",
              "7152       Josiah Tongogara  1.203429e+09\n",
              "7153      Langton Towungana  1.246280e+09\n",
              "7154      Sengezo Tshabangu  1.228478e+09\n",
              "\n",
              "[7155 rows x 2 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki_info = pd.read_csv('wiki_information.csv')\n",
        "wiki_info\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, wiki_info['revid'] will contain a list of all the rev_ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "yTlUCVGhMihw",
        "outputId": "2d8a7012-ca19-408e-c1e2-51c2834788df"
      },
      "outputs": [],
      "source": [
        "list_of_outputs = []\n",
        "counter = 0\n",
        "\n",
        "for article in list(wiki_info['revid']):\n",
        "  print(f\"Getting LiftWing ORES scores for '{article}' with revid: {article}\")\n",
        "#\n",
        "#    Make the call, just pass in the article revision ID, email address, and access token\n",
        "  score = request_ores_score_per_article(article_revid=int(article),\n",
        "                                       email_address=\"dvabhinav31@gmail.com\",\n",
        "                                       access_token=ACCESS_TOKEN)\n",
        "  print(counter)\n",
        "  counter+=1\n",
        "  list_of_outputs.append(json.dumps(score,indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cell outputs above have been removed since they utilize too much space. Rerun them to get the response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we convert the string for each json into json and write it into a json file. \n",
        "\n",
        "Following is the structure of the json file: \n",
        "```\n",
        "{ \n",
        "  \"outputs\": [\n",
        "    {\n",
        "      \"enwiki\": {\n",
        "        \"models\": { \"articlequality\": { \"version\": \"0.9.2\" } },\n",
        "        \"scores\": {\n",
        "          \"1231655023\": {\n",
        "            \"articlequality\": {\n",
        "              \"score\": {\n",
        "                \"prediction\": \"Stub\",\n",
        "                \"probability\": {\n",
        "                  \"B\": 0.007563164541978764,\n",
        "                  \"C\": 0.010571998067933679,\n",
        "                  \"FA\": 0.0014567448768872152,\n",
        "                  \"GA\": 0.00350824677167893,\n",
        "                  \"Start\": 0.04243220742433865,\n",
        "                  \"Stub\": 0.9344676383171826\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    # many more such articles\n",
        "  ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#convert string to json\n",
        "list_of_outputs = [json.loads(x) for x in list_of_outputs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#write to json\n",
        "with open(\"ores_output.json\",\"w\") as file:\n",
        "    json.dump(list_of_outputs,file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
